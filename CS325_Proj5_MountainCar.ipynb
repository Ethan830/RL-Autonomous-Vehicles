{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ethan830/RL-Autonomous-Vehicles/blob/main/CS325_Proj5_MountainCar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klGNgWREsvQv"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/t81_558_class_12_4_atari.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzzbqc-JS2z9"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Deep RL: Q-Learning, DQN, and PPO\n",
        "* [Eugene Agichtein](https://www.cs.emory.edu/~eugene/) for CS325: Artificial Intelligence\n",
        "* Adapted from [Jeff Heaton](https://sites.wustl.edu/jeffheaton/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmDI-h7cI0tI"
      },
      "source": [
        "# Google CoLab Setup\n",
        "\n",
        "The following code ensures that Google CoLab is running the correct version of TensorFlow, and has the necessary Python libraries installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KQhYThvTCQC",
        "outputId": "2af012b9-b39d-490b-ebd8-9ea7eee5d428",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: using Google CoLab\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.6.0\n",
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "\u001b[33mWARNING: gymnasium 1.1.1 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (0.10.2)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python-opengl\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.14).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# HIDE OUTPUT\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "if COLAB:\n",
        "  !pip install stable-baselines3[extra] gymnasium\n",
        "  !pip install gymnasium[accept-rom-license,atari]\n",
        "  !pip install pyvirtualdisplay\n",
        "  !sudo apt-get install -y python-opengl ffmpeg\n",
        "  !sudo apt-get install -y xvfb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q-Learning in Gymnasium\n",
        "Gymnasium: https://gymnasium.farama.org/ is a more general and realistic virtual universe with many environments, such as robotic control, video games, and 3-d physics.\n",
        "\n",
        "Out of the box, Q-Learning does not deal with continuous inputs, such as a car's accelerator that can range from released to fully engaged. Additionally, Q-Learning primarily deals with discrete actions, such as pressing a joystick up or down. For now, we will apply regular Q-Learning to the Mountain Car problem from Gymnasium\n",
        "\n",
        "## Introducing the Mountain Car\n",
        "\n",
        "This section will demonstrate how Q-Learning can create a solution to the mountain car gym environment. The Mountain car is an environment where a car must climb a mountain. Because gravity is stronger than the car's engine, it cannot merely accelerate up the steep slope even with full throttle. The vehicle is situated in a valley and must learn to utilize potential energy by driving up the opposite hill before the car can make it to the goal at the top of the rightmost hill.\n",
        "\n",
        "First, it might be helpful to visualize the mountain car environment. The following code shows this environment."
      ],
      "metadata": {
        "id": "mQNmeE9hIc0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from PIL import Image\n",
        "\n",
        "# Create and initialize the MountainCar environment\n",
        "env = gym.make('MountainCar-v0', render_mode=\"rgb_array\")\n",
        "env.reset()\n",
        "\n",
        "# Render the environment's state to a numpy array\n",
        "frame = env.render()\n",
        "\n",
        "# Convert the numpy array to an image and display it\n",
        "image = Image.fromarray(frame)\n",
        "\n",
        "# Don't forget to close the environment when you're done!\n",
        "env.close()\n",
        "\n",
        "display(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "kqk2o7laIeki",
        "outputId": "08d3025c-0682-4f8a-d3b4-947b578e6a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=600x400>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mountain car environment provides the following discrete actions:\n",
        "\n",
        "* 0 - Apply left force\n",
        "* 1 - Apply no force\n",
        "* 2 - Apply right force\n",
        "\n",
        "The mountain car environment Observations are made up of the following continuous values:\n",
        "\n",
        "* state[0] - Position\n",
        "* state[1] - Velocity\n",
        "\n",
        "The car is not strong enough. It will need to use potential energy from the mountain behind it. The following code shows an agent that applies full throttle to climb the hill."
      ],
      "metadata": {
        "id": "54_nlA8TIlO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KZZnNZ1PPaRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import gymnasium as gymnasium\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "import numpy as np\n",
        "\n",
        "# Start virtual display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "# Create Mountain Car environment\n",
        "env = gymnasium.make('MountainCar-v0', render_mode=\"rgb_array\")\n",
        "env.metadata['render_fps'] = 30\n",
        "# Reset the environment\n",
        "env.reset()\n",
        "\n",
        "# Setup the wrapper to record the video\n",
        "video_callable=lambda episode_id: True\n",
        "env = RecordVideo(env, video_folder='./videos_mcar', episode_trigger=video_callable)\n",
        "\n",
        "# Run the environment until done\n",
        "\n",
        "truncated = False\n",
        "i=0\n",
        "while not truncated:\n",
        "  i+=1\n",
        "  action = 2\n",
        "  state, reward, terminated, truncated , info = env.step(action)\n",
        "  #print(f\"Step {i}: State={state}, Reward={reward}, term={terminated}, trunc={truncated}, info={info}\")\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIFSY7nVIbIl",
        "outputId": "2468a8dc-379f-438c-88ab-42785c3b35d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos_mcar folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the video\n",
        "video = io.open(glob.glob('videos_mcar/*.mp4')[0], 'r+b').read()\n",
        "encoded = base64.b64encode(video)\n",
        "ipythondisplay.display(HTML(data='''\n",
        "    <video width=\"640\" height=\"480\" controls>\n",
        "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "    </video>\n",
        "'''.format(encoded.decode('ascii'))))"
      ],
      "metadata": {
        "id": "leJtIgREPmwe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "7dc8a04d-4709-4244-a076-6c85ae8ec3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6970c3a309a8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Display the video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'videos_mcar/*.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r+b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ipythondisplay.display(HTML(data='''\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m<\u001b[0m\u001b[0mvideo\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"640\"\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"480\"\u001b[0m \u001b[0mcontrols\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Several hyperparameters are very important for Q-Learning. These parameters will likely need adjustment as you apply Q-Learning to other problems. Because of this, it is crucial to understand the role of each parameter.\n",
        "\n",
        "* **LEARNING_RATE** The rate at which previous Q-values are updated based on new episodes run during training.\n",
        "* **DISCOUNT** The amount of significance to give estimates of future rewards when added to the reward for the current action taken. A value of 0.95 would indicate a discount of 5% on the future reward estimates.\n",
        "* **EPISODES** The number of episodes to train over. Increase this for more complex problems; however, training time also increases.\n",
        "* **SHOW_EVERY** How many episodes to allow to elapse before showing an update.\n",
        "* **DISCRETE_GRID_SIZE** How many buckets to use when converting each continuous state variable. For example, [10, 10] indicates that the algorithm should use ten buckets for the first and second state variables.\n",
        "* **START_EPSILON_DECAYING** Epsilon is the probability that the agent will select a random action over what the Q-Table suggests. This value determines the starting probability of randomness.\n",
        "* **END_EPSILON_DECAYING** How many episodes should elapse before epsilon goes to zero and no random actions are permitted. For example, EPISODES//10  means only the first 1/10th of the episodes might have random actions."
      ],
      "metadata": {
        "id": "k9euFwaeIiDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.1\n",
        "DISCOUNT = 0.95\n",
        "EPISODES = 1000 #set to >=600 to ensure training works for this problem\n",
        "\n",
        "DISCRETE_GRID_SIZE = [10, 10]\n",
        "START_EPSILON_DECAYING = 0.5\n",
        "END_EPSILON_DECAYING = EPISODES//10"
      ],
      "metadata": {
        "id": "yfDLygsoJF6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We lets create the discrete buckets for state and build Q-table.\n",
        "\n",
        "> Add blockquote\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G0XDXNM-JRPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gymnasium.make(\"MountainCar-v0\")\n",
        "\n",
        "epsilon = 1\n",
        "epsilon_change = epsilon/(END_EPSILON_DECAYING - START_EPSILON_DECAYING)\n",
        "buckets = (env.observation_space.high - env.observation_space.low) \\\n",
        "    / DISCRETE_GRID_SIZE\n",
        "q_table = np.random.uniform(low=-3, high=0, size=(DISCRETE_GRID_SIZE\n",
        "                                                  + [env.action_space.n]))\n",
        "success = False"
      ],
      "metadata": {
        "id": "mJb8fU8wIenZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets setup Q-learning!"
      ],
      "metadata": {
        "id": "3CmpAKYuJU0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-Learning Implementation: Discretizing input and actions"
      ],
      "metadata": {
        "id": "5PbV6bFdIurl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# This function converts the floating point state values into\n",
        "# discrete values. This is often called binning.  We divide\n",
        "# the range that the state values might occupy and assign\n",
        "# each region to a bucket.\n",
        "def calc_discrete_state(state):\n",
        "    discrete_state = (state - env.observation_space.low)/buckets\n",
        "    return tuple(discrete_state.astype(int))\n",
        "\n",
        "# Run one game.  The q_table to use is provided.  We also\n",
        "# provide a flag to indicate if the game should be\n",
        "# rendered/animated.  Finally, we also provide\n",
        "# a flag to indicate if the q_table should be updated.\n",
        "def run_game(q_table, render, should_update):\n",
        "    done = False\n",
        "    discrete_state = calc_discrete_state(env.reset()[0])\n",
        "    success = False\n",
        "\n",
        "    while not done:\n",
        "        # Exploit or explore\n",
        "        if np.random.random() > epsilon:\n",
        "            # Exploit - use q-table to take current best action\n",
        "            # (and probably refine)\n",
        "            action = np.argmax(q_table[discrete_state])\n",
        "        else:\n",
        "            # Explore - t\n",
        "            action = np.random.randint(0, env.action_space.n)\n",
        "\n",
        "        # Run simulation step\n",
        "        new_state, reward, done, _, _ = env.step(action)\n",
        "\n",
        "        # Convert continuous state to discrete\n",
        "        new_state_disc = calc_discrete_state(new_state)\n",
        "\n",
        "        # Have we reached the goal position (have we won?)?\n",
        "        if new_state[0] >= env.unwrapped.goal_position:\n",
        "            success = True\n",
        "\n",
        "        # Update q-table\n",
        "        if should_update:\n",
        "            max_future_q = np.max(q_table[new_state_disc])\n",
        "            current_q = q_table[discrete_state + (action,)]\n",
        "            new_q = (1 - LEARNING_RATE) * current_q + LEARNING_RATE * \\\n",
        "                (reward + DISCOUNT * max_future_q)\n",
        "            q_table[discrete_state + (action,)] = new_q\n",
        "\n",
        "        discrete_state = new_state_disc\n",
        "\n",
        "        if render:\n",
        "            env.render()\n",
        "\n",
        "    return success\n"
      ],
      "metadata": {
        "id": "ac4l9xQ4LKLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the training!"
      ],
      "metadata": {
        "id": "vvn1E1H5LOjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "episode = 0\n",
        "success_count = 0\n",
        "\n",
        "# Loop through the required number of episodes\n",
        "while episode < EPISODES:\n",
        "    episode += 1\n",
        "    done = False\n",
        "\n",
        "    # Run the game.\n",
        "    success = run_game(q_table, False, True)\n",
        "\n",
        "    # Count successes\n",
        "    if success:\n",
        "        success_count += 1\n",
        "\n",
        "    # Move epsilon towards its ending value, if it still needs to move\n",
        "    if END_EPSILON_DECAYING >= episode >= START_EPSILON_DECAYING:\n",
        "        epsilon = max(0, epsilon - epsilon_change)\n",
        "\n",
        "print(success)"
      ],
      "metadata": {
        "id": "7Uu2iEjzJeER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Now lets test the trained agent"
      ],
      "metadata": {
        "id": "CBAtYxpIJU8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HIDE OUTPUT\n",
        "\n",
        "# Setup the wrapper to record the video\n",
        "env = gymnasium.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
        "video_callable=lambda episode_id: True\n",
        "env = RecordVideo(env, video_folder='./videos_mcar', episode_trigger=video_callable)\n",
        "\n",
        "run_game(q_table, True, False)\n",
        "\n",
        "# Display the video\n",
        "video = io.open(glob.glob('videos_mcar/*.mp4')[0], 'r+b').read()\n",
        "encoded = base64.b64encode(video)\n",
        "ipythondisplay.display(HTML(data='''\n",
        "    <video width=\"640\" height=\"480\" controls>\n",
        "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "    </video>\n",
        "'''.format(encoded.decode('ascii'))))"
      ],
      "metadata": {
        "id": "MM7BxhfUJkUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspecting the Q-Table\n",
        "\n",
        "We can also display the Q-table. The following code shows the agent's action for each environment state. As the weights of a neural network, this table is not straightforward to interpret. Some patterns do emerge in that direction, as seen by calculating the means of rows and columns. The actions seem consistent at both velocity and position's upper and lower halves."
      ],
      "metadata": {
        "id": "dgHfQDOZJolf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(q_table.argmax(axis=2))\n",
        "\n",
        "df.columns = [f'v-{x}' for x in range(DISCRETE_GRID_SIZE[0])]\n",
        "df.index = [f'p-{x}' for x in range(DISCRETE_GRID_SIZE[1])]\n",
        "df"
      ],
      "metadata": {
        "id": "ShURmdgnJrZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBc9lj9VWWtZ"
      },
      "source": [
        "## Training the DQN Agent\n",
        "\n",
        "Great! we are done with basic Q-Learning. However, its not going to scale to larger/more complex environments.\n",
        "\n",
        "We are now ready to train the DQN, which is like Q-Learning, but the Q values are estimated using a neural network. Depending on how many episodes you wish to run through, this process can take many hours. This code will update both the loss and average return as training occurs. As training becomes more successful, the average return should increase. The losses reported reflecting the average loss for individual training batches."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating policies for large state spaces is a task that Deep Q-Learning Networks (DQN) can usually handle. Neural networks can generalize these states and learn commonalities. Unlike a table, a neural network does not require the program to represent every combination of state and action. A DQN maps the state to its input neurons and the action Q-values to the output neurons. The DQN effectively becomes a function that accepts the state and suggests action by returning the expected reward for each possible action.\n",
        "\n",
        "To implement DQN and other algorithms, we can use the Stable Baselines library. It is designed for ease of use, offering a straightforward API to implement, experiment with, and extend upon cutting-edge RL methods."
      ],
      "metadata": {
        "id": "6NQB-5WPA3Yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import torch as th\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Create and initialize the MountainCar environment\n",
        "env = gym.make('MountainCar-v0', render_mode=\"rgb_array\")\n",
        "time_step = env.reset()\n",
        "print('Time step:')\n",
        "print(time_step)\n",
        "\n",
        "action = 1\n",
        "\n",
        "next_time_step = env.step(action)\n",
        "print('Next time step:')\n",
        "print(next_time_step)\n",
        "# Instantiate the agent\n",
        "#We can specify the network architecture for fully connected networks (MLPs)\n",
        "policy_net = dict(activation_fn=th.nn.ReLU, net_arch=[128]) #1 hidden layers, 128 neurons each\n",
        "dqn = DQN(\"MlpPolicy\", env, verbose=1,\n",
        "          policy_kwargs=policy_net,\n",
        "          learning_rate=0.001, gamma=1, batch_size=128)"
      ],
      "metadata": {
        "id": "9pynBHuEB2q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the agent\n",
        "dqn.learn(total_timesteps=2e4) #can be very large for big problems to hopefully succeed\n",
        "#however, DQN is known not to work well for this problem...\n",
        "\n",
        "# Save the agent\n",
        "dqn.save(\"dqn_mcar\")"
      ],
      "metadata": {
        "id": "G3sh7xBbRvwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a fresh environment for evaluation\n",
        "eval_env = gym.make('MountainCar-v0')\n",
        "\n",
        "# Evaluate the agent\n",
        "mean_reward, std_reward = evaluate_policy(dqn, eval_env, n_eval_episodes=10)\n",
        "\n",
        "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")"
      ],
      "metadata": {
        "id": "9kZGghk1Rwxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize actions\n",
        "\n",
        "visulaize the mountain ageint and save in a video."
      ],
      "metadata": {
        "id": "Q9KA0XWiDQVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the wrapper to record the video\n",
        "env = gymnasium.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
        "video_callable=lambda episode_id: True\n",
        "video_env = RecordVideo(env, video_folder='./videos_mcar_dqn', episode_trigger=video_callable)\n",
        "\n",
        "# Run the environment until done\n",
        "\n",
        "truncated = False\n",
        "terminated=False\n",
        "i=0\n",
        "obs, info = video_env.reset()\n",
        "while not truncated and (not terminated):\n",
        "    action, _ = dqn.predict(obs, deterministic=True)\n",
        "    obs, reward, terminated, truncated , info = video_env.step(action)\n",
        "video_env.close()\n",
        "\n",
        "# Display the video\n",
        "video = io.open(glob.glob('videos_mcar_dqn/*.mp4')[0], 'r+b').read()\n",
        "encoded = base64.b64encode(video)\n",
        "ipythondisplay.display(HTML(data='''\n",
        "    <video width=\"640\" height=\"480\" controls>\n",
        "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "    </video>\n",
        "'''.format(encoded.decode('ascii'))))"
      ],
      "metadata": {
        "id": "Zotmzc9uUujq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PPO Policy\n",
        "\n",
        "However, DQN is not the best we can do. In particular, direct policy optimization, e.g., with Actor-Critic models, can be more effective, and is the only approach possible with continuous action outpus.  PPO is a variant of Actor-Critic where policies are optimized within particular \"trust region\".\n",
        "See lecture slides for details.\n",
        "\n",
        "Conveniently, Stable baselines implements these models!"
      ],
      "metadata": {
        "id": "H_aYRc7kFYbf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq8VWUBFz5_t"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "import base64\n",
        "from IPython import display as ipythondisplay\n",
        "from pathlib import Path\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.vec_env import VecFrameStack\n",
        "\n",
        "\n",
        "env = gymnasium.make(\"MountainCar-v0\", render_mode=\"rgb_array\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the agent, here we use Proximal Policy Optimization (PPO)\n",
        "policy_net = dict(activation_fn=th.nn.ReLU, net_arch=[64,64]) #2 hidden layers, 64 neurons each\n",
        "ppo = PPO('MlpPolicy', env, verbose=1,\n",
        "          policy_kwargs=policy_net,\n",
        "          learning_rate=0.001, gamma=0.99, batch_size=128)\n"
      ],
      "metadata": {
        "id": "0UxhBNrN62J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the agent\n",
        "TIMESTEPS = 1e5\n",
        "ppo.learn(total_timesteps=TIMESTEPS)\n",
        "\n",
        "# Save the model\n",
        "ppo.save(f\"mcar_ppo_model\")\n",
        "\n",
        "# Evaluate the trained agent\n",
        "mean_reward, std_reward = evaluate_policy(ppo, env, n_eval_episodes=10)\n",
        "\n",
        "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")\n",
        "\n",
        "# Don't forget to close the environment when you are done\n",
        "env.close()"
      ],
      "metadata": {
        "id": "PVfU8MIM68AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7-XpPP99Cy7"
      },
      "source": [
        "Lets watch the agent drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Qpx5qvI3wD0"
      },
      "outputs": [],
      "source": [
        "# Setup the wrapper to record the video\n",
        "#env = gymnasium.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
        "env = gymnasium.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
        "video_callable=lambda episode_id: True\n",
        "video_env = RecordVideo(env, video_folder='./videos_mcar_ppo', episode_trigger=video_callable)\n",
        "\n",
        "# Record the environment\n",
        "video_folder = '/content/videos_mcar_ppo'\n",
        "obs, info = video_env.reset()\n",
        "\n",
        "# Run the environment until done\n",
        "\n",
        "\n",
        "done = False\n",
        "while not done:\n",
        "    action, _states = ppo.predict(obs, deterministic=True)\n",
        "    obs, rewards, done, truncated, info = video_env.step(action)\n",
        "    env.render()\n",
        "env.close()\n",
        "\n",
        "# Display the video\n",
        "video = io.open(glob.glob('videos_mcar_ppo/*.mp4')[0], 'r+b').read()\n",
        "encoded = base64.b64encode(video)\n",
        "ipythondisplay.display(HTML(data='''\n",
        "    <video width=\"640\" height=\"480\" controls>\n",
        "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "    </video>\n",
        "'''.format(encoded.decode('ascii'))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The end! you now know how to train Q-Learning agents, DQN agents and Policy Network agents in Gymnasium. Onwards to the main assignment"
      ],
      "metadata": {
        "id": "Jhr3LseYe5GV"
      }
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9 (torch)",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}